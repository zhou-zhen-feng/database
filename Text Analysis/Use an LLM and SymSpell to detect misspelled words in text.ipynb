{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b3e3a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import wordnet\n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "# 下载NLTK资源（首次运行时）\n",
    "nltk.download('wordnet', quiet=True)\n",
    "nltk.download('omw-1.4', quiet=True)\n",
    "\n",
    "# 加载WordNet词典\n",
    "def load_wordnet_dictionary(all_pos=False):\n",
    "    \"\"\"加载WordNet词典并构建词形索引\"\"\"\n",
    "    print(\"正在加载WordNet词典...\")\n",
    "    word_dict = defaultdict(list)\n",
    "    \n",
    "    # 获取所有有效词性标签\n",
    "    if all_pos:\n",
    "        pos_tags = [\n",
    "            wordnet.NOUN,    # 'n'\n",
    "            wordnet.VERB,    # 'v'\n",
    "            wordnet.ADJ,     # 'a'\n",
    "            wordnet.ADJ_SAT, # 's' (卫星形容词)\n",
    "            wordnet.ADV      # 'r'\n",
    "        ]\n",
    "    else:\n",
    "        pos_tags = [\n",
    "            wordnet.NOUN,    # 'n'\n",
    "            wordnet.VERB,    # 'v'\n",
    "            wordnet.ADJ,     # 'a'\n",
    "            wordnet.ADV      # 'r'\n",
    "        ]\n",
    "    \n",
    "    # 遍历所有词性\n",
    "    for pos in pos_tags:\n",
    "        try:\n",
    "            # 获取该词性的所有同义词集\n",
    "            synsets = list(wordnet.all_synsets(pos))\n",
    "            print(f\"正在处理词性 {pos} ({len(synsets)} 个同义词集)...\")\n",
    "            \n",
    "            # 使用tqdm显示进度\n",
    "            for synset in tqdm(synsets, desc=f\"词性 {pos}\"):\n",
    "                for lemma in synset.lemmas():\n",
    "                    word = lemma.name()\n",
    "                    word_dict[word].append(synset)\n",
    "        except Exception as e:\n",
    "            print(f\"加载词性 {pos} 时出错: {str(e)}\")\n",
    "    \n",
    "    print(f\"WordNet词典加载完成，唯一词形数: {len(word_dict)}\")\n",
    "    return word_dict\n",
    "\n",
    "# 初始化WordNet词典\n",
    "wordnet_dict = load_wordnet_dictionary()\n",
    "\n",
    "# 检查单词是否在WordNet中\n",
    "def is_word_in_wordnet(word):\n",
    "    \"\"\"检查单词是否存在于WordNet\"\"\"\n",
    "    return word in wordnet_dict\n",
    "\n",
    "# 检查单词完整性和拼写\n",
    "def is_complete_and_correct(word):\n",
    "    \"\"\"\n",
    "    检查条件：\n",
    "    1. 纯字母\n",
    "    2. WordNet中存在\n",
    "    3. 下划线拆分后各部分均存在\n",
    "    \"\"\"\n",
    "    if not word.isalpha():\n",
    "        return False, \"包含非字母字符\"\n",
    "    \n",
    "    if '_' in word:\n",
    "        parts = word.split('_')\n",
    "        for part in parts:\n",
    "            if not is_word_in_wordnet(part):\n",
    "                return False, f\"拆分错误: {part} 不在WordNet中\"\n",
    "        return True, \"拆分后各部分均在WordNet中\"\n",
    "    \n",
    "    return is_word_in_wordnet(word), \"单词存在于WordNet\"\n",
    "\n",
    "# 过滤每个种子词的相似词列表\n",
    "def filter_top_valid_words(similar_words_dict, max_results=20):\n",
    "    \"\"\"\n",
    "    过滤每个种子词的相似词列表，只保留前max_results个有效的单词\n",
    "    \n",
    "    参数:\n",
    "    - similar_words_dict: 包含种子词及其相似词的字典\n",
    "    - max_results: 每个种子词保留的有效相似词数量\n",
    "    \n",
    "    返回:\n",
    "    - 过滤后的字典，格式为 {种子词: [(有效词1, 相似度1), (有效词2, 相似度2), ...]}\n",
    "    \"\"\"\n",
    "    filtered_dict = {}\n",
    "    \n",
    "    # 使用tqdm显示处理进度\n",
    "    with tqdm(total=len(similar_words_dict), desc=\"处理种子词\") as pbar:\n",
    "        for seed_word, similar_words in similar_words_dict.items():\n",
    "            # 初始化过滤后的列表\n",
    "            filtered_words = []\n",
    "            \n",
    "            # 对每个相似词进行过滤\n",
    "            for word, score in similar_words:\n",
    "                # 检查单词是否有效\n",
    "                is_valid, reason = is_complete_and_correct(word)\n",
    "                \n",
    "                if is_valid:\n",
    "                    # 如果有效，添加到过滤后的列表\n",
    "                    filtered_words.append((word, score))\n",
    "                    \n",
    "                    # 达到最大数量时停止\n",
    "                    if len(filtered_words) >= max_results:\n",
    "                        break\n",
    "            \n",
    "            # 保存过滤后的结果\n",
    "            filtered_dict[seed_word] = filtered_words\n",
    "            \n",
    "            # 更新进度条\n",
    "            pbar.update(1)\n",
    "            pbar.set_postfix({seed_word: f\"{len(filtered_words)}/{min(max_results, len(similar_words))} 有效词\"})\n",
    "    \n",
    "    return filtered_dict\n",
    "\n",
    "# 主函数：处理inferior_similar_words_dict\n",
    "def process_inferior_words(inferior_dict, max_results=20):\n",
    "    \"\"\"处理inferior_similar_words_dict，保留每个种子词的前max_results个有效相似词\"\"\"\n",
    "    print(f\"开始处理 {len(inferior_dict)} 个种子词...\")\n",
    "    \n",
    "    # 应用过滤\n",
    "    filtered_dict = filter_top_valid_words(inferior_dict, max_results)\n",
    "    \n",
    "    # 输出结果统计\n",
    "    total_valid_words = sum(len(words) for words in filtered_dict.values())\n",
    "    print(f\"\\n处理完成！共保留 {total_valid_words} 个有效相似词\")\n",
    "    \n",
    "    return filtered_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6be37936-3fa8-4d40-8533-7292261573b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from symspellpy.symspellpy import SymSpell, Verbosity\n",
    "import inspect\n",
    "\n",
    "# 打印Verbosity枚举的所有成员\n",
    "print(\"Verbosity枚举可用值:\")\n",
    "for member in inspect.getmembers(Verbosity):\n",
    "    if not member[0].startswith('_'):\n",
    "        print(f\"- {member[0]}\")\n",
    "\n",
    "# 测试单词检查（使用实际存在的枚举值）\n",
    "test_word = \"the\"\n",
    "try:\n",
    "    # 尝试常见枚举值（按可能性排序）\n",
    "    for verbosity_name in [\"CLOSEST\", \"ALL\", \"TOP\"]:\n",
    "        verbosity = getattr(Verbosity, verbosity_name, None)\n",
    "        if verbosity:\n",
    "            suggestions = sym_spell.lookup(test_word, verbosity, max_edit_distance=0)\n",
    "            if suggestions:\n",
    "                print(f\"使用{verbosity_name}成功获取建议: {suggestions[0].term}\")\n",
    "                break\n",
    "    else:\n",
    "        raise AttributeError(\"无可用的verbosity值\")\n",
    "except Exception as e:\n",
    "    print(f\"测试失败: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2665a9c-e50c-458b-bb21-2e91e949d5a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from symspellpy.symspellpy import SymSpell, Verbosity\n",
    "import os\n",
    "\n",
    "# 词典文件路径（修改为你的实际路径）\n",
    "dictionary_path = r\"D:\\zhenfeng zhou\\自由的代价\\扩展种族主义词典\\full articles\\全文\\frequency_dictionary_en_82_765.txt\"\n",
    "bigram_path = r\"D:\\zhenfeng zhou\\自由的代价\\扩展种族主义词典\\full articles\\全文\\frequency_bigramdictionary_en_243_342.txt\"\n",
    "\n",
    "# 初始化SymSpell（设置严格匹配）\n",
    "sym_spell = SymSpell(\n",
    "    max_dictionary_edit_distance=0,  # 仅精确匹配（不允许拼写错误）\n",
    "    prefix_length=7\n",
    ")\n",
    "\n",
    "# 加载词典\n",
    "def load_dictionaries():\n",
    "    \"\"\"加载词典并验证完整性\"\"\"\n",
    "    if os.path.exists(dictionary_path):\n",
    "        sym_spell.load_dictionary(dictionary_path, term_index=0, count_index=1)\n",
    "        print(f\"单词语典加载完成，条目数: {len(sym_spell.words)}\")\n",
    "    else:\n",
    "        raise FileNotFoundError(f\"单词语典不存在: {dictionary_path}\")\n",
    "    \n",
    "    if os.path.exists(bigram_path):\n",
    "        sym_spell.load_bigram_dictionary(bigram_path, term_index=0, count_index=2)\n",
    "        print(f\"二元语法词典加载完成，条目数: {len(sym_spell.bigrams)}\")\n",
    "    else:\n",
    "        print(\"未找到二元语法词典，仅使用单词语典\")\n",
    "\n",
    "# 按相似度从高到低排序\n",
    "top_similar_word.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# 检查单词是否在词典中（使用CLOSEST枚举）\n",
    "def is_word_in_dictionary(word):\n",
    "    suggestions = sym_spell.lookup(\n",
    "        word,\n",
    "        verbosity=Verbosity.CLOSEST,  # 使用CLOSEST替代EXACT\n",
    "        max_edit_distance=0\n",
    "    )\n",
    "    return len(suggestions) > 0\n",
    "\n",
    "# 检查单词完整性和拼写\n",
    "def is_complete_and_correct(word):\n",
    "    \"\"\"\n",
    "    检查条件：\n",
    "    1. 纯字母\n",
    "    2. 非词干（词典存在）\n",
    "    3. 下划线拆分后各部分正确\n",
    "    \"\"\"\n",
    "    if not word.isalpha():\n",
    "        return False, \"包含非字母字符\"\n",
    "    \n",
    "    if '_' in word:\n",
    "        parts = word.split('_')\n",
    "        for part in parts:\n",
    "            if not is_word_in_dictionary(part):\n",
    "                return False, f\"拆分错误: {part}\"\n",
    "        return True, \"拆分后均正确\"\n",
    "    \n",
    "    return is_word_in_dictionary(word), \"单词存在\"\n",
    "\n",
    "# 过滤单词（取前20个有效词）\n",
    "def filter_words(words_with_scores, max_results=20):\n",
    "    filtered = []\n",
    "    for word, score in words_with_scores:\n",
    "        is_valid, reason = is_complete_and_correct(word)\n",
    "        if is_valid:\n",
    "            filtered.append((word, score, reason))\n",
    "        if len(filtered) >= max_results:\n",
    "            break\n",
    "    return filtered\n",
    "\n",
    "# 主流程\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        load_dictionaries()\n",
    "        filtered_results = filter_words(top_similar_word)\n",
    "        \n",
    "        print(\"\\n过滤后有效单词（前20个）:\")\n",
    "        for i, (word, score, reason) in enumerate(filtered_results, 1):\n",
    "            print(f\"{i}. {word} (相似度: {score:.4f}) - {reason}\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        import traceback\n",
    "        print(f\"执行错误: {str(e)}\")\n",
    "        traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8d90aee-5f24-4ccc-adef-21cdc4e38f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(api_key='你的api-key')\n",
    "\n",
    "def filter_similar_words(similar_words):\n",
    "    \"\"\"\n",
    "    similar_words 是一个列表，形如：\n",
    "    [(\"thief\", 0.8), (\"burglars\", 0.79), (\"robbers\", 0.71), ...]\n",
    "    \"\"\"\n",
    "\n",
    "    word_list_str = \"\\n\".join([f\"{word} (相似度: {score:.3f})\" for word, score in similar_words])\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "你是一个拼写和词形专家。请根据下面的单词列表，从相似度高到低依次判断，帮我筛选出拼写正确且完整的单词。\n",
    "请过滤掉：\n",
    "- 明显拼写错误的词\n",
    "- 可以包含复合词\n",
    "- 词干、不完整的词\n",
    "- 对带下划线的词，请拆分后判断每个单词是否拼写正确且完整（如果其中有一个拼写错误或者不完整，就过滤掉整个词）\n",
    "请严格按原列表顺序返回满足条件的前20个单词，只返回单词列表，不要解释。\n",
    "\n",
    "单词列表：\n",
    "{word_list_str}\n",
    "\"\"\"\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=[\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    filtered_words_text = response.choices[0].message.content.strip()\n",
    "    filtered_words = [line.strip() for line in filtered_words_text.split(\"\\n\") if line.strip()]\n",
    "\n",
    "    # 根据模型筛选结果，从原列表找对应相似度，返回元组列表\n",
    "    word_score_dict = dict(similar_words)\n",
    "    filtered_word_scores = [(w, word_score_dict[w]) for w in filtered_words if w in word_score_dict]\n",
    "\n",
    "    return filtered_word_scores\n",
    "\n",
    "# 示例调用\n",
    "similar_words = []\n",
    "\n",
    "result = filter_similar_words(similar_words)\n",
    "print(\"筛选后结果（含相似度）：\", result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
